{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest\n",
    "\n",
    "1. create a few different Tree Ensemble Methods\n",
    "2. visualize feature importances, and compare individual trees from a Random Forest to see the differences in the features they were trained on.\n",
    "\n",
    "Note that the model is already good enough! So no need to go through GridSearch, and optimization of random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./data_prep.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth= 10) \n",
    "tree.fit(X_train_all, y_train)\n",
    "pred = tree.predict(X_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(model):\n",
    "    n_features = X_train_all.shape[1]\n",
    "    plt.figure(figsize=(10,10))\n",
    "    features = dict(zip(X_train_all.columns, model.feature_importances_))\n",
    "    sorted_fim = sorted(features.items(), key=lambda x: x[1])\n",
    "    sorted_im = [i[1] for i in sorted_fim]\n",
    "    sorted_f = [i[0] for i in sorted_fim]\n",
    "    \n",
    "    plt.barh(range(n_features), sorted_im, align='center') \n",
    "    plt.yticks(np.arange(n_features), sorted_f) \n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "\n",
    "plot_feature_importances(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, pred)}\")    #already a perfect model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = X_train_all.drop(labels = 'Popularity', axis= 1, inplace = False)\n",
    "X_test_np = X_test_all.drop(labels = 'Popularity', axis= 1, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth = 10) \n",
    "tree.fit(X_train_np, y_train)\n",
    "pred = tree.predict(X_test_np)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, pred)}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth= 10)\n",
    "rf.fit(X_train_np, y_train)\n",
    "\n",
    "print(rf.score(X_train_np, y_train))\n",
    "print(rf.score(X_test_np, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Cross Validation Score for Random Forest Classifier\n",
    "mean_rf_cv_score = np.mean(cross_val_score(rf, X_train_np, y_train, cv=3))  \n",
    "mean_rf_cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grid = {\n",
    "    'n_estimators': [5, 10, 30, 100],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "rf_grid_search = GridSearchCV(rf, rf_param_grid, cv=3)\n",
    "rf_grid_search.fit(X_train_np, y_train)\n",
    "\n",
    "print(rf_grid_search.best_score_) #Testing Accuracy\n",
    "print(rf_grid_search.best_params_) #Optimal Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf_grid_search.score(X_test_np, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rf_cv_score = np.mean(cross_val_score(rf_grid_search, X_train_np, y_train,cv =5))\n",
    "\n",
    "print(f\"Mean Cross Validation Score: {mean_rf_cv_score * 100}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
